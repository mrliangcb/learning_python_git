
# 2章.pandas用法

```python
import numpy as np #
import pandas as pd
import os
```

## 1.Series
pandas表格，每一列都是一个series ,可以由list或者nparray产生  一个series有 value值，有行标序号
### (1)创建series 单个列  
(1.1)由list创建series:  
```python
se=pd.Series([4,3,6,10],index=['a','b','c','d'])  #index为行序号
print(a)
print(se.values)
print(se.index)
```
values : 获得list形式的内容  
(1.2)由dict创建series:  
```python
se2={'liming':25,'wangwu':35,'xiaoming':19} 
												
index=['china','wangwu','france']  #这是显示设置,
se2=pd.Series(se2,index) #根据字典生成series，然后选择一部分显示
#series的时候，value只有一个。而dataframe的时候value是一个list  
#liming wangwu就是index,也是key
```
结果为:  
```python
china      NaN
wangwu    35.0
france     NaN
dtype: float64
```


### (2)索引方法  
```python
se['a']  
se[['a']]  
```
维数与返回类型的关系 : 二维表示与自己相同的类型，一维表示比自己低的类型  
从低到高 : np或者list   series  dataframe  

条件索引:  
```python
se[se>0]
```
上面相当于se[[true,false]]里面是判断的结果bool型  

判断:  
```python
panduan='a' in se  
```
返回true  false

查找缺失值  
pd.isnull(se3).index.tolist() #获得行标，之后再根据行标做操作  
pd.isnull(se3)这部分是得到bool型series  

### (3)修改series
(3.1) 填充缺失   
.fillna()  #可以是value，或者数组，series  

(3.2) 修改行标
se3.index=['a','b','c']  #要把全部行标写出来
```
a    25
b    35
c    19
dtype: int64
```

se3.reindex(['a','b'],fill_value=0) #选择行标来显示行，缺失的填充0  
```
a    25
b    35
dtype: int64
```


## 2.dataframe表格  

### (1) 创建  
-- 从np创建df:  
```py
a=np.array([[1,2,3],[4,5,6],[7,8,9]])  
index=['a','b','c']  
column=['ming','wang','liang']  
df1=pd.DataFrame(a,index=['a','b','c'],columns=column)  
```
-- 也可以从list创建df

print(df1)
```
   ming  wang  liang
a     1     2      3
b     4     5      6
c     7     8      9
```

给行和列名加一个统一的名字  左上角  
df1.index.name='name'  
df1.columns.name='data'  

df1.reindex([1,'a','b']) #选择显示的顺序和项目  
df1.reindex(columns=[1,'xiaoming','liming']) #选择显示的顺序和项目  

-- 从字典建立df
pd.DataFrame({'ones': np.ones(len(df))}) 


### 查看属性
df1.dtypes()
df1.describe()


### (2) 索引  
```py
df1.values  #返回一个二维的list  
df1['age']  #取出age这一列 一维的，所以返回series  
df1[['age']]  #返回df  
df1[['age']].loc[[1,2]] #loc[行标，列名] 或者loc[行标 或行标list 或者index类型也可以]
print(df1[['age','score']])  #取多行  
df1.loc[:,['age','score']]  #这种方法最常用，返回df  
df1.ix[['liming'],['age']] #少用这种
df1.loc[:4,df1.columns[2]]  用第2个列名来查，不用具体列名

# 过滤 条件筛选  
a=df1[df1['age']==18] #返回一个df，可以用|和&来连接判断语句，不是and or 或者&&  ||，而且记得一个条件要一个()    df1[(条件一) & (条件二)]  
a=df1[df1.loc[:,'age']==18]   与上面等价，返回df  

与series对比: a=df1.ID[df1['ID']==18] 返回一个series

#查找空值  
df[df.loc[:,'age'].isnull()].index()  返回下标,index类型,可以.tolist()
或者看是否==np.nan  


``

### (3) 修改    
单值修改，批量修改，apply修改
index的不可修改性，不能单独修改  
df[]判断和修改值不能一步做完，要分开，先根据条件获得行标list，然后再对查找list进行修改，删除  
```py
df1['age']=1 #对整一列赋1  
df1['age']=[32,40,19]  #批量赋值  可以np.list,series  

#只修改一个值
df1.age.loc[3]=50    
df1.loc[3,'age']=50 #可以把原nan值修改成新的值  

#批量修改
#会对行标进行匹配再赋值
b=pd.Series(np.arange(12))
df2[['age']]=b 
#可以试一下从df1取出某条件的一些行，修改值之后，又放回原df1  
#可能赋值series或者df的时候，会匹配index，如果赋值list的时候，直接赋值，不考虑匹配
data.loc[[1,2,3],'ID']=data.loc[[1,2,3],'Hand']  


#对行标进行排序 
a=np.arange(0,data.shape[0])
data.index=[a]
#index是直接修改行标值，reindex是进行排序 没有修改  

df11=df11.rename(columns={'名称':'a'})  
#修改列名  

#按某值排列
a=data.sort_values(by='Age' , ascending=True)

#查找和修改分两步  
a=df[df.ID<2].index.tolist()
df.loc[a,"ID"]=赋值一个series

#修改数据类型 
df["Customer Number"] = df["Customer Number"].astype("int") #修改之后赋值给自己

#转换成np  np.array(……)
#转换成list   .tolist()
```

### (4) 增加  
1、concat与merge与join  
result=pd.concat([x,y],axis=1)#1是水平拼接，0是垂直，而且拼接的时候对应index的拼接 #拼接经常和df覆盖并用  
test=pd.concat([df1,df2],keys=['df1','df2'])  #外index为df1,df2 层次化索引  
参数:  
> keys=list  
> names=['','']  

2.增加行
```py
#方法一  
df3=df1.append(df2) #按照列名排列，把df2追加到df1后面    
#方法二  
for i in range(5):
     df.loc[i] = [randint(-1,1) for n in range(3)]
#方法三:
df3.loc['new'] = ['a','a','a','a'] 
#方法四:append字典
res = res.append([{'第一列':10.0}], ignore_index=True)
```
		

### (5) 删除    
```py
del df1['birth'] #删除列  
data.drop(['ID'],axis=1,inplace=True)  
data.drop([0,1,2,3],axis=0) #删除行  
a=a.drop_duplicates(subset=['代码'])  # 删除重复的行
a=a.dropna(how='all')    # 把series中值为nan的值去掉
   
```

### (6) 文件打开 
**重点**   
(6.1)方法一:用pandas读  txt或者csv  

```py
path=r'.\test.txt'  
df1 = pd.read_csv(path,nrows=None)  
# 遇到逗号算一个列分割，遇到\n转下一行
- 可添加属性: 
> converters = {u'a':str,u'b':str} 对于'a','b'列，指定value为str类型 如果没有conver，则会自动转为float或者int
> dtype=str 指定全部value都是str型  对于0001这种数据，如果不设置str，则读成1
> names=["a","b","c"]  定义列名，没有定义的话，取数据的第一行作为列名  建立df的时候用的是columns
> nrows=None  #取前面多少行
> index_col=0 =0表示不加上0,1,2,3这种默认的index，而是用第一列作为index    
> sep=',' 逗号作为分隔符  遇到逗号算一个列分割
> header=None  指的是说明这个文件第一行就是数据，没有列名。默认是有的，就会把第一行当做列名
> 
```

```py
pd.read_table(r'',encoding='ansi')  
# encoding='utf8' 

pd.read_excel()   这种是读标准的excel文件，非逗号空格符的  csv文件是自带逗号作为分隔  
```
(6.2)方法二:用open读   
```py
with open(r'.\test.txt', 'r') as f:
    lines = f.readlines() #每行作读作一个str ，['第一行','第二行']
    print(lines)
    tokens = [i.rstrip('\n').split(',') for i in lines] #rstrip('内容') 删除字符串末尾的'内容'
    print(tokens) 
	
pd.DataFrame(tokens[1:],columns=tokens[0])

# tokens0 = [i.rstrip('\n').split(',')[0] for i in lines]  只取出第一列  
# 经过split,  a=[[一行],[二行],['1','2']]
# idx_label = dict((int(idx), label) for idx, label in tokens)#创建字典，数字：‘名字’
```

(6.3)读入文件后，查看属性 
```py
print('1.读前5行',df1.head(5))#tail看尾巴
print('\n2.形状',df1.shape)
print('\n3.有哪些列:',df1.columns)
print('\n4.每个列的数据类型:',df1.columns)
print('\n5.读values',df1.values) #返回二维list 
np.array(df.loc[:,-1]) #转成numpy矩阵，上面是转list
data.as_matrix()   #转成numpy 数组

```

(6.4)修改数据类型，属性  
```py
# (1) numpy: array.astype(np.float32)
# (2) 强转换: df.astype(int)
# (3) series改变属性
pd.to_numeric(df1['a'], errors='coerce')  #默认转为float64  coerce表示无效数据变为nan, errors='ignore'表示对无效数不做改变
# (4) 用apply函数，返回int(元素)，再赋值给原df
```

### (7) 文件保存  
**重点**   


### (8) lambda公式  善于做计算和修改  
```py
def my_test(a, b):
    return a + b
df1['Value'] = df1.apply(lambda row: my_test(row['1'], row['2']), axis=1)   
#比for循环高效，相当于每次循环输入一个row，然后经过N次循环之后，把N次结果垂直堆叠起来 

df.apply(lambda column: (column - column.mean()) / column.std()) #现写匿名函数
 
```

```py
def classes(row):
    print('传入的df:',row)
    #for i in range(len(df)):
    if row['score'] < 60:
        row['level'] = 'C'
    elif row['score'] > 90:
        row['level'] = 'A'
    else:
        row['level'] = 'B'
    return row
df = df.apply(lambda row: classes(row), axis=1)#循环传入行，循环完了之后就把结果concat起来，打包返回，
#前面第一种方法是return 一个数，这里是return一个行
#所以最终分别获得 series和df

```


### (9)统计功能  
```py
 #按照某列的大小排列  
    #df.sort_values(by='Age')  
    
    #求相关性  
    #df.corr()  
    
    #计数  
    #df.ID.count()#相当于series.count()  
    
    #统计频次  
    #df.Age.value_counts(ascending=True)#参数表示排列顺序  
    
    #统计某个列  0出现的次数  
    #dict(df[0]value_counts())  
    value_count() 的参数：  
    
    #求和  
    #df.["列名"].sum(axis=0)  #0就是列，1就是行   
  
#(1) normalize : boolean, default False             如果为True，则返回的对象将包含唯一值的相对频率。  
#sort : boolean, default True             按值排序  
#ascending : boolean, default False        按频率计数升序排序  
#bins : integer, optional    而不是数值计算，把它们分成半开放的箱子，一个方便的pd.cut，只适用于数字数据  
#dropna : boolean, default True          不包括NaN的数量。  

    #普通排列  
    #np.sort(a,axis=0)  
    
    #用df进行统计画图  
    s=pd.DataFrame({'all':[1,2,3],  
        'P1':[1,2,3],'P2':[1,2,3],  
        'P3':[1,2,3]},index=['0-30','30-60','60-82'])#大家都有的属性是放在'',关键字，私有的叫做index  
    print(s)  
    s.plot(kind='bar')
    plt.show()
    
    #跟value_counts结合
    #s=pd.DataFrame(data.Age.value_counts)
    #s.plot(kind='bar') 
```

















